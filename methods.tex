\section{Methods} \label{sec:methods}

\subsection{Preliminaries}
There are some useful concepts to keep in mind in order to understand the creation and use of a DCEL data structure.  It starts with a set of edges, pair of two vertices, start and end, which define its orientation. We assume every edge is an straight line segment.

An edge usually bounds two faces, so we need two pairs of pointers for it. It is convenient to view the different sides of an edge as two distinct half-edges, so that we have a unique next half-edge and previous half-edge for every edge. This also means that a half-edge bounds only one face. The two half-edges we get for a given edge are called twins.  A face is a polygonal region whose boundary is formed by connected edges and vertices.  The main idea is that the faces of the resulting DCEL can be able to reconstruct the original polygons.

The current challenge is the construction of a distributed and scalable DCEL structure that allows the querying of overlay operations, such as intersection and difference, over a large set of polygons.  The main idea of the solution is to partition the edges from each of the polygons using a spatial data structure (for instance, a quadtree).  Edges contained at each section of the partitioning will be the input of a local DCEL which will store the information of the vertices, half-edges and faces for their edges clipped to the boundary of its spatial partition.  Each local DCEL can be seen as an individual structure which can be queried and the solution will be later merged with the other local DCELs in their neighbourhood to complete the final answer. 

\subsection{Partition strategy} \label{sec:strategy}
In many cases, the operations provide by a DCEL could involve large spatial datasets.  Our aim is to offer a solution to deal with data volumes that the current sequential solution are unable to process.  In order to reach that goal we are purposing a partition strategy to build a scalable DCEL in a parallel fashion.  

The main idea of the strategy is to split the study area into a number of cells which could be processed independently in a local basis. We can take the case of overlay operations over layers of polygons as an example to explains the details. In the sequential approach, the DCEL for each layer will be built and then both will be merged to generate a structure where the operator can be applied.  

Our goal is to create DCELs for each layer in parallel to be able to solve large datasets the sequential alternatives are unable.  The proposal can be summarized in the following steps: (i) Partition the input polygons and build local DCEL representations of them at each partition; (ii) Merge the local DCELs for each layer together locally scaling the processing cost; (iii) Overlay operations will be run over the local merged DCELs to finally be collected back to mix and generate the final answer.  

The proposed partition schema is illustrated in figure \ref{fig:overlay_parted}.  First, we will use a sample of edges from both layers to create a set of cells which will spatially partition the space into disjoint areas.  In the example, a simple grid is used but any spatial index can be applied (in our experiments we use quadtrees for better balance and data distribution).  We will use those cells to clip the input polygons to generate new ones that will lie inside of the boundaries of the cell.  Although it will increase the number of edges and the size of the data, we expect that that the gain during parallel processing will make the addition worthwhile.

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=\textwidth]{figures/01-OverlayParted}
    \caption{Partition schema.}\label{fig:overlay_parted}
    \Description[Partition schema]{This figure illustrates the partition schema used to distribute the data.}
\end{figure*}

Now each cell have the enough data to build a DCEL representation of the polygons for each layer.  Data for each cell will be marked appropriately and submitted to different nodes to be processed in parallel.  Note that the same partition schema (set of cells) is used in both layers.  That is important due to it allows one-to-one matching between corresponding partitions in both layers.

During the local DCEL construction for individual layers, it is straightforward the connection between the edges inside of each polygon.  From the inputs, it can easily be identified the position of each edge relate to its next and previous edges and to which face (polygon) the edge belongs.  Each edge is converted to a half-edge and their pointers are update accordingly.  However, a query to identify the twin pointer of each half-edge is still needed given that the input polygons do not provide which polygons are in its neighborhood. The matching is done through a self-join query among the current half-edges to pair those which share the same vertices in opposite directions.

However, when we pair the partitions from the both layers, we got two local DCELs (each representing the polygons for each layer) and the processing we need now is a merge between both of them.  It requires: (i) Identify the intersection points between the half-edges of each local DCEL and add them as new vertices; (ii) Split those half-edges involve in an intersection with a recently added vertex (prune duplicates if needed); (iii) Traverse the list of vertices and update their incident half-edge list; (iv) Update the pointers for next and previous half-edges in those affected by the splits; (v) Update the list of faces and their corresponding labels.

Figure \ref{fig:part2} depicts an overview of the process taking as example the polygons and edges of partition 2 of figure \ref{fig:overlay_parted}.  Similarly, figure \ref{fig:merged_dcel} shows the full result of the merged DCEL once all the partitions have processed their corresponding edges. Note that red half-edges have been introduced artificially by the partition schema but they are marked accordingly to be used in the collect back process when we need to unify the results after the application of the overlay operations.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/02-Part2}
    \caption{Merge of local DCEL for partition 2.}\label{fig:part2}
    \Description[Merge of local DCELs for a particular partition]{This figure shows how the local DCELs works in a particular example.}
\end{figure}

\begin{figure}[!ht]
    \centering
    \input{figures/merged_dcel}    
    \caption{Result of the merged DCEL.}\label{fig:merged_dcel}
    \Description[Result of the merged DCEL]{This figure shows what would be the results of the merge DCEL procedure.}
\end{figure}

At this point, we have access to a distributed spatial data structure which collects the individual DCEL representations of the full study area at local basis.  It is easy to see that we can run overlay operations in parallel over the local DCELs and then just collect and merge the results to unify a final answer.  For example, figure \ref{fig:overlay_parted2} illustrates the process to query for the intersection results over the input polygons described in figure \ref{fig:overlay_parted}.  More details about the implementation of the overlay operators are discussed later in section \ref{sec:overlay}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\linewidth]{figures/03-OverlayParted2}
    \caption{Example of an overlay operation querying the distributed DCEL.} \label{fig:overlay_parted2}
    \Description[An example of an overlay operation]{This figure shows an example of an overlay operation querying the distributed DCEL.}
\end{figure}

Figure \ref{fig:overlay_operations} shows the results of the five overlay operations supported by the scalable DCEL.  To obtain the results we query locally the DCEL filtering the faces according to the characteristics of its label.  For intersection ($A \cap B$), it filters just faces where its label contains both letters (A and B); On the other hand, for symmetric difference ($A \bigtriangleup B$), it filters faces where its labels contains just one of the letters (A or B).  For the case of difference between the layers ($A \setminus B$ or $B \setminus A$), it filters faces and labels according to the requested letter (either A or B). In the case of union ($A \cup B$), all the faces are retrieved. 

\begin{figure*}[!ht]
    \centering
    \input{figures/overlay_operations}
    \caption{Results of the overlay operations supported by the scalable DCEL.}\label{fig:overlay_operations}
    \Description[Results of the overlay operations]{This figure shows the results of the overlay operations supported by the scalable DCEL.}
\end{figure*}

\subsection{Parallel DCEL Computation}
In this section explain:

* how the edges from the polygons are partitioned \\

During the partition process, the edges of each polygon are attached with pointers to their next and previous edge according to their order in the polygon vertices.  As explained before, a spatial index is used to assign each edge to a particular cell.  Each edge is queried in the spatial data structure and it is labeled with the cell where it is contained.  If a edge covers multiples cell it is duplicated in each one but clipped to the corresponding cell boundary.  In addition, edges representing the boundary of the cell are added to complement the edges enclosed in each cell.  Those artificial edges are marked accordingly to be removed during the merge stage.

* how to integrated the intersection of the edges and the boundary of the cells at partition time \\

The edges of the cell added at this stage are useful to complete the local DCEL.  It will allow that the resulting DCEL will enclose the full area of the cell and the matching with the local DCEL of the other layer during the merge process.  The edges which intersect the boundary of the cell will be connected to the edges of the boundary to form closed faces in the resulting local DCEL.

* extract the edges which are connected and are fully contained by the cell, they can be reported directly.\\

As the edges have been partitioned accordingly to the spatial index, each cell will contain all the data they need to process and compute a DCEL locally in a parallel fashion. In each case, after the DCEL is built those edges and faces that are not involved with the edges introduced by the boundary of the cell could be reported directly and they do not need additional analysis.  It is, most of the edges in the middle of the cell which do not have contact to the boundary are ready for the merging stage and they do not need additional processing.




* extract the edges which are connected but remains open because their are cut by the border of the cell.\\
* identify those edges which intersect the boundary and used to create new edges in the borders of the cell.\\  
* run the a variation of the sequential algorithm to connect the open edges and the edges from the borders of the cell.\\

prepare some graphics to explain the steps

\subsection{Cell inside polygon problem} \label{sec:anomalies}
The main goal of the proposal is to be able to divide the problem into smalls partitions for efficient processing.  Each partition collects the needed data and it is able to build its local DCEL without the need of query other partitions.  However, under this partition strategy, a new problem arises.  It happens when the partition schema (i.e. a quadtree) deliver a cell where no edges for any of the input layers are located.  The problem is even more complicated when a just hole in located inside a cell (figure \ref{fig:emptycells}).  The problem is that the empty cell (or the empty portion in the case of holes) has no access to which polygon it belongs making its corresponding labeling impossible.  

\begin{figure}[!ht]
    \centering
    \includegraphics[page=1, width=0.5\textwidth]{figures/cellinpolygon/emptycells.pdf}
    \includegraphics[page=2, width=0.5\textwidth]{figures/cellinpolygon/emptycells.pdf}
    \caption{Example of empty cell and empty cell with holes cases.}\label{fig:emptycells}
    \Description[Examples of empty cells]{This figure shows some examples of of empty cell and empty cell with holes cases.}
\end{figure}

To solve the problem, an algorithm is proposed to find the next cell in the valid information about the polygon they are contained.  It is based on the branch information of the cell inside of the spatial index structure used during partition, also know as lineage (see figure \ref{fig:lineage_example} for an example).  For the sack of explanation, we will assume we use a quadtree, but the proposal could be easily adapted to other data structures such as grids.

After the partitioning strategy, a set of the cells is available with the following information: an unique cell identifier (id); a lineage, a string which provides the position and depth of the cell into the spatial index; and an envelope which is a polygon representation (a rectangle) of the boundaries of the cell.

The key of the proposal is to identify the centroid of the parent cell from the empty cell in question.  That point will allow us to retrieve the neighbour cells which can easily be queried if they have edges to extract the needed polygon information.  If all of them are still empty, we proceed to choose that one with the deepest level and recursively repeat the process.  Eventually, a non-empty cell will emerge and all the involved empty cells can be updated.  Figure \ref{fig:emptycellexample} shows a three iteration run of the algorithm with the example of figure \ref{fig:emptycells}.

\begin{figure}[!ht]
    \centering
    \includegraphics[page=1, width=0.49\linewidth]{figures/cellinpolygon/example}
    \includegraphics[page=2, width=0.49\linewidth]{figures/cellinpolygon/example}
    \includegraphics[page=3, width=0.49\linewidth]{figures/cellinpolygon/example}
    \caption{Three iterations of the proposed algorithm to find the next cell with valid edges from a empty cell.} \label{fig:emptycellexample}
    \Description[Iteration of the proposed algorithm]{This figure shows three iterations of the proposed algorithm to find the next cell with valid edges from a empty cell.}
\end{figure}

The details and pseudo code of the algorithm can be seen at appendix \ref{app:emptycells}.  We based of proposal in the following lemma and used it to proved our point with the subsequent proof.

\begin{lemma}
Four cells at the same level can not be empty.  At least one of them must have edges in order to force the split.
\end{lemma}

\begin{proof}
The $\textsc{getCellsInCorner}$ function will query the interior corner of a cell according to its position, that is the centroid of its cell parent.  The only cells which can intersect that point are cells at the same level of the current cell or their children.  If the 3 cells returned by $\textsc{getCellsInCorner}$ are empty, at least one of them must have a deeper level that the current cell.  Following that cell guarantees that the search space will be shrank at each iteration.  Eventually, the algorithm will reach the maximum level of the quadtree where all the involved cells will have the same level and, therefore, at least one of them must have edges.
\end{proof}

\subsection{Distributed overlay operators} \label{sec:overlay}
Once the distributed DCEL is ready for analysis, we have to take care on how it should be queried in order to take advantage of such distribution.  Section \ref{sec:strategy} shows the initial strategy to partition the study area and how each partition holds a section of the DCEL clipped to the cell boundary of that partition.  It is straightforward that we could query locally each of the sections but, once it is done, we should unify the results among contiguous partitions.

Faces in the interior of a partition (those which do not touch the boundary) are safe to be reported.  However, for those faces which share a half-edge with the boundary, there is a high chance that another section of that face is present in a contiguous partition and has to be checked.  

We execute a merging stage on the set of faces which touch the boundaries of each partition.  It performs a reduce operation pairing faces with the same label and dissolving their geometries.  For example, in figure \ref{fig:overlay_parted2}, it can be seen how faces in different partitions but with the same label are merged into final results by removing their common half-edges. 

\subsection{Alternative methods for overlay}\label{sec:alternative_methods}

To evaluate the best alternatives during the reduce/merge stage, three different approaches were evaluated to glue together segments of faces which could be located in different partitions.  As it was mentioned earlier, those closed segments which form auto-contained faces inside of each partition are immediately reported and there is no need for additional processing.  However, those segments which touch the border of the cell in their partition must be post-processed to evaluate if they could be extended with segments in the neighborhood partitions.

The first naive approach was to collect those segments touching the borders in a master/root node which sequentially will combine segments with the same label and concatenate them accordingly in order to create the final face.  It is a straightforward method but could be really costly if the number of partitions and the subsequent number of segments touching borders are large.

As an alternative, it is proposed to do an intermediate step with a parameter introduced by the user were a level in the quadtree structure is given.  Following this parameter, the segments in partitions below the given level are collect them in intermediate nodes of the quadtree were can be evaluated partially.  The goal of this step is that part of the work can be distributed in a larger number of nodes as a previous step before to be sent to the master/root node for final evaluation.  It is expected that most of the work can be done in this intermediate step.  However, those partitions which are located above of the user defined level still have to be evaluated in an individual node.

It is clear that it will create an optimization issue: if we choose a level low in the structure it can be evaluated in a larger number of intermediate nodes (taking advantage of parallelism) but, at the same time, a large number of partitions will be located above of that threshold and they will be evaluated by an unique node which can dominate the execution time.  On the other hand, if a level is selected high in the quadtree, just a few number of partitions will have to be evaluated in that unique node, but the number of intermediate nodes will also be reduced and the execution time for their evaluation will increase.

Last method take a different approach.  It partitions the set of segments at each partition by their label itself.  It is, it will reorganize the segments using their labels as the key.  The resulting dataset will put together those segments which share the same label in the same partition and they will be evaluated in the same node.  In this case, the cost of the partition should be evaluated but it is expected than the number and size of the resulting partitions will take much more advantage of parallelism.

\subsection{Alternative methods for unbalance data}\label{sec:unbalance}
It has been noted that the most time consuming operating is the overlay of the data once the individual DCELs have been created for each layer.  Particularly, when the combination of half-edges from each layer is performing at each cell, the most critical task is finding the intersection points between the two set of half-edges. It has been also noted that in some cases the number of half-edges from each layer can be quiet unbalance.

In the traditional approach, a common sweep-line approach is performed scanning both sets of half-edges from left to right (scanning the x-axis) inside each cell and the corresponding intersections points are reported in order to continue with the creation of the merged DCEL. This approach does not consider the fact that in some cell one of the sets can be larger than the other and there is no need to scan all the half-edges in many cases.

An alternative approach is proposed for those cases.  It start detecting which sets contains more half-edges and which has more probability to overlap the smaller one in the x-axis. Then, it performs a simple scan in the smaller to extract the wide of this dataset and returned in the form of intervals over the x-axis.  It has to be noted that a smaller dataset can extend in several intervals over the bigger dataset and it has been managed accordingly.  

With each interval, it is possible to locate the point in the x-axis where the sweep-line algorithm should start scanning from the bigger set and compared with the half-edges from de smaller one. On those cases where the bigger and smaller set differ considerably in size, it is possible to save time due to the fact that many sections of the bigger set do not required to be scanned nor compared with the smaller set.